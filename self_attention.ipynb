{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "let us consider a sentence \"my name is saugat\""
      ],
      "metadata": {
        "id": "PWXIxqCnlRsz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bWTYdkIHktVK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l,d_k,d_v=4,8,8  #l=length=\"my name is saugat\"=4 words , d_k=8,d_v=8 means size of vector=8\n"
      ],
      "metadata": {
        "id": "kxqyk-LvlP7m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#now we need 3 main things for attention. they are:\n",
        "\n",
        "\n",
        "1.   q=query=what do i want\n",
        "2.   k=key=what can i offer\n",
        "3.   v=value=what i actually offer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o8PUm_lgl8pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now lets define q,k,v as random for now\n",
        "q=np.random.randn(l,d_k)\n",
        "k=np.random.randn(l,d_k)\n",
        "v=np.random.randn(l,d_v)\n"
      ],
      "metadata": {
        "id": "_y-v9n94mIJ3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"q={q}\")\n",
        "print(f\"k={k}\")\n",
        "print(f\"v={v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDA3meH9mRSS",
        "outputId": "d3f4104b-f8f3-493e-ac46-8b91b3c6f30f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "q=[[-1.15873707 -1.12292661  1.53719464  2.69145197 -0.21722089 -0.57057489\n",
            "   0.39686817  2.57939819]\n",
            " [-1.13092477 -0.04624123 -1.21146713  0.22530178 -0.01245056  1.69367177\n",
            "  -0.79877572 -0.48267566]\n",
            " [ 2.23581263 -0.47178513  0.95159789  0.34461021 -1.82811743  0.67997646\n",
            "   0.05341568  0.97523561]\n",
            " [-0.18395556  0.83001059 -2.05269769  1.62774787 -0.22820215 -1.25004423\n",
            "  -0.05574591  0.73908923]]\n",
            "k=[[ 0.53702096  2.98720983 -0.08718354  1.20646853 -0.97903543  1.57424501\n",
            "   1.3398012  -0.92501926]\n",
            " [ 1.92510878 -1.09181966 -0.78434258  0.24847455 -0.1529471  -0.28065854\n",
            "   0.67195458 -0.97122017]\n",
            " [-1.03892145  0.78427791 -1.35731363  0.86191042 -0.47354578  0.76130175\n",
            "  -0.03671953  0.63143657]\n",
            " [-0.53205992  1.38977394  0.19709206 -0.02607246 -0.73646591 -0.65656239\n",
            "   0.55806003 -0.64903416]]\n",
            "v=[[-0.13599561  0.04135474  2.11439876  0.24253907 -0.39828407 -1.6500081\n",
            "   0.64308759  0.55259813]\n",
            " [ 0.05992497  0.83490384  0.27801984  0.43445172  0.88956349  3.00592478\n",
            "  -0.7271053  -0.08332308]\n",
            " [-1.01629969  0.42466558 -0.88070762 -0.92980485  0.69781517 -0.41275816\n",
            "   1.54067858  1.05610224]\n",
            " [-0.12683142 -1.32498769 -0.49736559  0.45469565 -0.88388432  0.74812078\n",
            "   0.67449836  0.90720994]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#now lets define self attention mechanism:\n",
        "self_attention=softmax(q.k(transpose)/sqrt(d base k)+M)\n",
        "new_V=self_attention.V"
      ],
      "metadata": {
        "id": "JqOqRApumr_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.matmul(q,k.T) #k.T=k(transpose)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRDiQtQOmf6e",
        "outputId": "c41ef609-ac47-4607-99c8-073a37b31344"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.40337575, -3.58671758,  1.83912343, -1.62934799],\n",
              "       [ 1.68670443, -1.66187496,  3.99704961, -0.94251342],\n",
              "       [ 2.1538507 ,  3.33602341, -1.69023543, -1.3699463 ],\n",
              "       [ 2.02059773,  0.38457712,  4.65633999,  1.28238409]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so why do we devide by sqrt(d base k)??\n",
        "\n",
        "*   it is so that we can minimize the variance\n",
        "\n"
      ],
      "metadata": {
        "id": "4Zq5_uV-nne7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#before applying variance\n",
        "q.var(), k.var(), np.matmul(q,k.T).var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5sjNra6nhKT",
        "outputId": "4955b54d-5002-45d6-9776-4e2e9ac7c470"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.4370473931251346, 1.016542583159945, 6.118019208434202)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now lets devide\n",
        "scaled=np.matmul(q,k.T)/math.sqrt(d_k)\n",
        "q.var(), k.var(), scaled.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKcd6HJ6oBF8",
        "outputId": "1cfb2918-780e-46d1-ca01-cf905184569e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.4370473931251346, 1.016542583159945, 0.764752401054275)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled #notice the reduction on variance of the product"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AwC-DYOoIUt",
        "outputId": "6e9abd53-1483-4032-95c2-a3b6811d659e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.20327504, -1.26809616,  0.65022833, -0.57606151],\n",
              "       [ 0.59634007, -0.58756153,  1.41317044, -0.33322882],\n",
              "       [ 0.76150122,  1.17946239, -0.59758847, -0.48434916],\n",
              "       [ 0.71438918,  0.13596855,  1.64626479,  0.45339124]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#masking: usually masking is required for decoder part , not for encoder, but lets just define it for now\n",
        "\n",
        "*   This is to ensure words don't get context from words generated in the future.\n",
        "    \n",
        "\n",
        "*   Not required in the encoders, but required int he decoders\n",
        "\n"
      ],
      "metadata": {
        "id": "ywuq-dJWopTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask=np.tril(np.ones((l,l)))\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntAQuluBoeSB",
        "outputId": "a868d7e9-796f-47c5-f7d5-558fac8f6d0a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [1., 1., 0., 0.],\n",
              "       [1., 1., 1., 0.],\n",
              "       [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask[mask==0]=-np.infty\n",
        "mask[mask==1]=1\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-HdK-vnpoaQ",
        "outputId": "559f1ac4-5e48-455f-e0ea-5af8492b8ebc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1., -inf, -inf, -inf],\n",
              "       [  1.,   1., -inf, -inf],\n",
              "       [  1.,   1.,   1., -inf],\n",
              "       [  1.,   1.,   1.,   1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 -inf -inf -inf in 1st row means \"my\"\n",
        "1 1 1 -inf -inf means \"my name\"////ans so on"
      ],
      "metadata": {
        "id": "XMP9qE5LqGhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaled+mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsnAJIhqpzzu",
        "outputId": "b01ccf07-a858-4fe5-aee2-4a9dd673d5d6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.20327504,        -inf,        -inf,        -inf],\n",
              "       [ 1.59634007,  0.41243847,        -inf,        -inf],\n",
              "       [ 1.76150122,  2.17946239,  0.40241153,        -inf],\n",
              "       [ 1.71438918,  1.13596855,  2.64626479,  1.45339124]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#now lets add softmax function here\n",
        "softmax is used to conver the vector into probability distribution so that they can add up to one\n"
      ],
      "metadata": {
        "id": "dWdSn-u7qcue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T"
      ],
      "metadata": {
        "id": "7t3OK3GDq1mT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention=softmax(scaled+mask)"
      ],
      "metadata": {
        "id": "SGMx1QIHqZXi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrXXpmhTqx1v",
        "outputId": "6fce2e26-1c2d-47c5-95ab-1da191caa5a7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.        , 0.        , 0.        ],\n",
              "       [0.7656486 , 0.2343514 , 0.        , 0.        ],\n",
              "       [0.36026218, 0.54718843, 0.09254938, 0.        ],\n",
              "       [0.20532476, 0.11514271, 0.52137447, 0.15815807]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_v=np.matmul(attention,v)\n",
        "new_v\n",
        "#after applying attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT4IydzOq_yh",
        "outputId": "73ad09b3-ca76-4774-f7bc-359775832460"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.13599561,  0.04135474,  2.11439876,  0.24253907, -0.39828407,\n",
              "        -1.6500081 ,  0.64308759,  0.55259813],\n",
              "       [-0.09008135,  0.22732409,  1.68404078,  0.28751407, -0.09647519,\n",
              "        -0.55888369,  0.32198097,  0.4035691 ],\n",
              "       [-0.11026173,  0.51105081,  0.83235821,  0.23905174,  0.40785452,\n",
              "         1.01217123, -0.02359462,  0.2512284 ],\n",
              "       [-0.57095546,  0.11647654, -0.07169047, -0.3130395 ,  0.24467874,\n",
              "        -0.08955743,  0.95826876,  0.79797535]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#before apply attention\n",
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DAm3AgyrX5j",
        "outputId": "c76720d3-d9b8-42cc-eaff-6c86c3714a90"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.13599561,  0.04135474,  2.11439876,  0.24253907, -0.39828407,\n",
              "        -1.6500081 ,  0.64308759,  0.55259813],\n",
              "       [ 0.05992497,  0.83490384,  0.27801984,  0.43445172,  0.88956349,\n",
              "         3.00592478, -0.7271053 , -0.08332308],\n",
              "       [-1.01629969,  0.42466558, -0.88070762, -0.92980485,  0.69781517,\n",
              "        -0.41275816,  1.54067858,  1.05610224],\n",
              "       [-0.12683142, -1.32498769, -0.49736559,  0.45469565, -0.88388432,\n",
              "         0.74812078,  0.67449836,  0.90720994]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now lets functionize it\n",
        "def softmax(x):\n",
        "  return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T\n",
        "\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask=None):\n",
        "  d_k= q.shape[-1]\n",
        "  scaled=np.matmul(q,k.T)/math.sqrt(d_k)\n",
        "\n",
        "  if mask is not None:\n",
        "    scaled=scaled+mask\n",
        "\n",
        "  attention=softmax(scaled)\n",
        "  new_v=np.matmul(attention,v)\n",
        "  return new_v,attention\n"
      ],
      "metadata": {
        "id": "5BF4Mbw5rbKo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values, attention = scaled_dot_product_attention(q, k, v, mask=mask)\n",
        "print(\"Q\\n\", q)\n",
        "print(\"K\\n\", k)\n",
        "print(\"V\\n\", v)\n",
        "print(\"New V\\n\", values)\n",
        "print(\"Attention\\n\", attention)#here we used mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2drc_EwsiXc",
        "outputId": "ec280db4-62f6-4db2-ad22-56d66f23a229"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q\n",
            " [[-1.15873707 -1.12292661  1.53719464  2.69145197 -0.21722089 -0.57057489\n",
            "   0.39686817  2.57939819]\n",
            " [-1.13092477 -0.04624123 -1.21146713  0.22530178 -0.01245056  1.69367177\n",
            "  -0.79877572 -0.48267566]\n",
            " [ 2.23581263 -0.47178513  0.95159789  0.34461021 -1.82811743  0.67997646\n",
            "   0.05341568  0.97523561]\n",
            " [-0.18395556  0.83001059 -2.05269769  1.62774787 -0.22820215 -1.25004423\n",
            "  -0.05574591  0.73908923]]\n",
            "K\n",
            " [[ 0.53702096  2.98720983 -0.08718354  1.20646853 -0.97903543  1.57424501\n",
            "   1.3398012  -0.92501926]\n",
            " [ 1.92510878 -1.09181966 -0.78434258  0.24847455 -0.1529471  -0.28065854\n",
            "   0.67195458 -0.97122017]\n",
            " [-1.03892145  0.78427791 -1.35731363  0.86191042 -0.47354578  0.76130175\n",
            "  -0.03671953  0.63143657]\n",
            " [-0.53205992  1.38977394  0.19709206 -0.02607246 -0.73646591 -0.65656239\n",
            "   0.55806003 -0.64903416]]\n",
            "V\n",
            " [[-0.13599561  0.04135474  2.11439876  0.24253907 -0.39828407 -1.6500081\n",
            "   0.64308759  0.55259813]\n",
            " [ 0.05992497  0.83490384  0.27801984  0.43445172  0.88956349  3.00592478\n",
            "  -0.7271053  -0.08332308]\n",
            " [-1.01629969  0.42466558 -0.88070762 -0.92980485  0.69781517 -0.41275816\n",
            "   1.54067858  1.05610224]\n",
            " [-0.12683142 -1.32498769 -0.49736559  0.45469565 -0.88388432  0.74812078\n",
            "   0.67449836  0.90720994]]\n",
            "New V\n",
            " [[-0.13599561  0.04135474  2.11439876  0.24253907 -0.39828407 -1.6500081\n",
            "   0.64308759  0.55259813]\n",
            " [-0.09008135  0.22732409  1.68404078  0.28751407 -0.09647519 -0.55888369\n",
            "   0.32198097  0.4035691 ]\n",
            " [-0.11026173  0.51105081  0.83235821  0.23905174  0.40785452  1.01217123\n",
            "  -0.02359462  0.2512284 ]\n",
            " [-0.57095546  0.11647654 -0.07169047 -0.3130395   0.24467874 -0.08955743\n",
            "   0.95826876  0.79797535]]\n",
            "Attention\n",
            " [[1.         0.         0.         0.        ]\n",
            " [0.7656486  0.2343514  0.         0.        ]\n",
            " [0.36026218 0.54718843 0.09254938 0.        ]\n",
            " [0.20532476 0.11514271 0.52137447 0.15815807]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values, attention = scaled_dot_product_attention(q, k, v, mask=None)\n",
        "print(\"Q\\n\", q)\n",
        "print(\"K\\n\", k)\n",
        "print(\"V\\n\", v)\n",
        "print(\"New V\\n\", values)\n",
        "print(\"Attention\\n\", attention)#here we didnt use mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WikGPt6lsm3i",
        "outputId": "3938d854-00b8-493c-a968-f0a8710362d2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q\n",
            " [[-1.15873707 -1.12292661  1.53719464  2.69145197 -0.21722089 -0.57057489\n",
            "   0.39686817  2.57939819]\n",
            " [-1.13092477 -0.04624123 -1.21146713  0.22530178 -0.01245056  1.69367177\n",
            "  -0.79877572 -0.48267566]\n",
            " [ 2.23581263 -0.47178513  0.95159789  0.34461021 -1.82811743  0.67997646\n",
            "   0.05341568  0.97523561]\n",
            " [-0.18395556  0.83001059 -2.05269769  1.62774787 -0.22820215 -1.25004423\n",
            "  -0.05574591  0.73908923]]\n",
            "K\n",
            " [[ 0.53702096  2.98720983 -0.08718354  1.20646853 -0.97903543  1.57424501\n",
            "   1.3398012  -0.92501926]\n",
            " [ 1.92510878 -1.09181966 -0.78434258  0.24847455 -0.1529471  -0.28065854\n",
            "   0.67195458 -0.97122017]\n",
            " [-1.03892145  0.78427791 -1.35731363  0.86191042 -0.47354578  0.76130175\n",
            "  -0.03671953  0.63143657]\n",
            " [-0.53205992  1.38977394  0.19709206 -0.02607246 -0.73646591 -0.65656239\n",
            "   0.55806003 -0.64903416]]\n",
            "V\n",
            " [[-0.13599561  0.04135474  2.11439876  0.24253907 -0.39828407 -1.6500081\n",
            "   0.64308759  0.55259813]\n",
            " [ 0.05992497  0.83490384  0.27801984  0.43445172  0.88956349  3.00592478\n",
            "  -0.7271053  -0.08332308]\n",
            " [-1.01629969  0.42466558 -0.88070762 -0.92980485  0.69781517 -0.41275816\n",
            "   1.54067858  1.05610224]\n",
            " [-0.12683142 -1.32498769 -0.49736559  0.45469565 -0.88388432  0.74812078\n",
            "   0.67449836  0.90720994]]\n",
            "New V\n",
            " [[-0.66754664  0.10334255 -0.40984974 -0.43496469  0.31731781 -0.00650124\n",
            "   1.08493187  0.87456369]\n",
            " [-0.62256505  0.18542612  0.0024861  -0.39086718  0.2786193  -0.34530949\n",
            "   1.05289796  0.82628248]\n",
            " [-0.11181783  0.33862404  0.70748066  0.25930338  0.28654423  0.98737362\n",
            "   0.04196497  0.3128332 ]\n",
            " [-0.57095546  0.11647654 -0.07169047 -0.3130395   0.24467874 -0.08955743\n",
            "   0.95826876  0.79797535]]\n",
            "Attention\n",
            " [[0.09811848 0.09196008 0.62620579 0.18371566]\n",
            " [0.25226276 0.07721314 0.57094998 0.09957413]\n",
            " [0.3264291  0.49580066 0.08385785 0.0939124 ]\n",
            " [0.20532476 0.11514271 0.52137447 0.15815807]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xOYToEZJssnZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}